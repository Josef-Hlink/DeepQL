{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3: Exploration Strategies\n",
    "\n",
    "In this notebook, we will explore the different exploration strategies that we have implemented in the `agents.exploration` module.\n",
    "We have already seen the $\\varepsilon$-greedy strategy in the previous notebooks, but we want to see if we can do better.\n",
    "Specifically, we examine the Boltzmann (softmax) and UCB (UCB1 formula) strategies.\n",
    "\n",
    "Because in previous experiments, we have observed that the combination of Experience Replay and the use of a target network is able to yield promising results, we will use these two techniques for all three exploration strategies.\n",
    "Apart from the exploration strategies (and annealing schemes), all settings are identical to the ones found in `2_randomwarmup.ipynb`.\n",
    "\n",
    "For both $\\varepsilon$-greedy and Boltzmann, we will use the same annealing schemes as in `2_randomwarmup.ipynb`:\n",
    "  - `AS1`: $\\varepsilon$ (or $\\tau$) is annealed from 1 to 0.01 over 80% of the training episodes.\n",
    "  - `AS4`: $\\varepsilon$ (or $\\tau$) is annealed from 1 to 0.1 over 50% of the training episodes.\n",
    "\n",
    "For UCB, we use a constant exploration parameter, which we call $\\zeta$.\n",
    "Because we have not had the time to tune this parameter, we will use a very simple value: $\\zeta = 1$."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "from dql.utils.namespaces import P, LC\n",
    "from dql.utils.datamanager import ConcatDataManager\n",
    "from dql.utils.plotter import ColorPlot, LossPlot, ComparisonPlot\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if we have the data.\n",
    "\n",
    "Should be EG and BM for both annealing schemes, and UC for annealing scheme 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runIDs = [f for f in os.listdir(P.data) if f.startswith('EA')]\n",
    "print('\\n'.join(runIDs))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if the parameters are correct.\n",
    "We check for the run using the `EG` config, but it doesn't really matter which one we use; the parameters are (near-)identical for all three configs.\n",
    "For the first annealing scheme, we print the full summary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ConcatDataManager('EA1-EG').printSummary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `EA0` & `EA4` runs only differ in annealing scheme, so we load and print these separately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in ConcatDataManager('EA0-UC').loadSummary().params.annealingScheme.items():\n",
    "    print(f'{k}: {v}')\n",
    "print()\n",
    "for k, v in ConcatDataManager('EA4-EG').loadSummary().params.annealingScheme.items():\n",
    "    print(f'{k}: {v}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function to easily get all figures for a given run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runNames = {'EG': f'{LC.e}-greedy', 'BM': 'Boltzmann', 'UC': 'UCB'}\n",
    "\n",
    "def getFigs(runID: str, exp: int) -> tuple[plt.Figure]:\n",
    "    expID, expName = {\n",
    "        0: ('EA0', 'Annealing scheme 0'),\n",
    "        1: ('EA1', 'Annealing scheme 1'),\n",
    "        4: ('EA4', 'Annealing scheme 4')\n",
    "    }[exp]\n",
    "\n",
    "    title = f'| {runNames[runID]}\\n{expName}'\n",
    "    DM = ConcatDataManager(f'{expID}-{runID}')\n",
    "\n",
    "    R = DM.loadRewards()\n",
    "    fR = ColorPlot(R, label='reward', title=title).getFig()\n",
    "\n",
    "    A = DM.loadActions()\n",
    "    AB = np.abs((A / np.sum(A, axis=2, keepdims=True))[:, :, 0] - .5) * 2\n",
    "    fAB = ColorPlot(AB, label='action bias', title=title).getFig()\n",
    "\n",
    "    L = DM.loadLosses()\n",
    "    fL = LossPlot(L, title=title).getFig()\n",
    "    return fR, fAB, fL"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### $\\varepsilon$-greedy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runID = 'EG'\n",
    "rewardFig, actionBiasFig, lossFig = getFigs(runID, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rewardFig, actionBiasFig, lossFig = getFigs(runID, 4)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Boltzmann"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runID = 'BM'\n",
    "rewardFig, actionBiasFig, lossFig = getFigs(runID, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rewardFig, actionBiasFig, lossFig = getFigs(runID, 4)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### UCB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runID = 'UC'\n",
    "rewardFig, actionBiasFig, lossFig = getFigs(runID, 0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "# redefine runIDS to only include EG and BM get the correct order\n",
    "runIDs = ['EA1-EG', 'EA4-EG', 'EA1-BM', 'EA4-BM', 'EA0-UC']\n",
    "for runID in runIDs:\n",
    "    DM = ConcatDataManager(runID)\n",
    "    R = DM.loadRewards()\n",
    "    A = DM.loadActions()\n",
    "    AB = np.abs((A / np.sum(A, axis=2, keepdims=True))[:, :, 0] - .5) * 2\n",
    "    data.append((R, AB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = ComparisonPlot(data, labels=runIDs, title='Exploration Strategies').getFig()\n",
    "fig.savefig(Path(P.plots) / 'E-C.png', dpi=500, bbox_inches='tight')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
